{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sgd.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMu48kzPSrEel/7EmzowmyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janewen134/tensorflow_self_improvement/blob/after_class_revision/sgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_sP_Ee7wRFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
        "\n",
        "# 导入所需模块\n",
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time  ##1##"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blCa10yuUEnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 导入数据，分别为输入特征和标签\n",
        "x_data = datasets.load_iris().data\n",
        "y_data = datasets.load_iris().target"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7o4YM-4UJvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
        "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
        "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
        "np.random.shuffle(x_data)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y_data)\n",
        "tf.random.set_seed(116)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYD0wDBGVF7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b4d2dc7b-b5ca-4856-8148-d2d64bfe5888"
      },
      "source": [
        "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
        "x_train = x_data[:-30]\n",
        "y_train = y_data[:-30]\n",
        "x_test = x_data[-30:]\n",
        "y_test = y_data[-30:]\n",
        "# Python的每个对象都分为可变和不可变，主要的核心类型中，数字、字符串、元组是不可变的，列表、字典是可变的。\n",
        "# 对不可变类型的变量重新赋值，实际上是重新创建一个不可变类型的对象，\n",
        "# 并将原来的变量重新指向新创建的对象（如果没有其他变量引用原有对象的话（即引用计数为0），原有对象就会被回收）\n",
        "# 执行 i += 1 时，内存地址都会变化，因为int 类型是不可变的。\n",
        "print(hex(id(x_data)))\n",
        "print(hex(id(x_train)))\n",
        "print(hex(id(x_test)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0x7f2d91ee1710\n",
            "0x7f2d8a397170\n",
            "0x7f2d8a3971c0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IX6zNzMVchB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "x_test = tf.cast(x_test, tf.float32)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ_ZI-cEZI5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIKbiCFjZ1tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 生成神经网络的参数，4个输入特征，故输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
        "# 用tf.Variable()标记参数可训练\n",
        "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
        "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
        "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n",
        "\n",
        "lr = 0.1  # 学习率为0.1\n",
        "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
        "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
        "epoch = 500  # 循环500轮\n",
        "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5hQ2mJpf7nN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6fda8b1c-4fa1-48b7-c0fb-b7d0f5700f35"
      },
      "source": [
        "# 训练部分\n",
        "now_time = time.time()  ##2##\n",
        "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
        "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
        "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
        "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
        "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
        "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
        "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
        "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
        "        # 计算loss对各个参数的梯度\n",
        "        grads = tape.gradient(loss, [w1, b1])\n",
        "\n",
        "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad\n",
        "        w1.assign_sub(lr * grads[0])  # 参数w1自更新\n",
        "        b1.assign_sub(lr * grads[1])  # 参数b自更新\n",
        "\n",
        "    # 每个epoch，打印loss信息\n",
        "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
        "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
        "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
        "\n",
        "    # 测试部分\n",
        "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
        "    total_correct, total_number = 0, 0\n",
        "    for x_test, y_test in test_db:\n",
        "        # 使用更新后的参数进行预测\n",
        "        y = tf.matmul(x_test, w1) + b1\n",
        "        y = tf.nn.softmax(y)\n",
        "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
        "        # 将pred转换为y_test的数据类型\n",
        "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
        "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
        "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
        "        # 将每个batch的correct数加起来\n",
        "        correct = tf.reduce_sum(correct)\n",
        "        # 将所有batch中的correct数加起来\n",
        "        total_correct += int(correct)\n",
        "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
        "        total_number += x_test.shape[0]\n",
        "    # 总的准确率等于total_correct/total_number\n",
        "    acc = total_correct / total_number\n",
        "    test_acc.append(acc)\n",
        "    print(\"Test_acc:\", acc)\n",
        "    print(\"--------------------------\")\n",
        "total_time = time.time() - now_time  ##3##\n",
        "print(\"total_time\", total_time)  ##4##"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 0.2821310982108116\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 1, loss: 0.25459614023566246\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 2, loss: 0.22570250928401947\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 3, loss: 0.21028399094939232\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 4, loss: 0.19942265003919601\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 5, loss: 0.18873637914657593\n",
            "Test_acc: 0.5\n",
            "--------------------------\n",
            "Epoch 6, loss: 0.17851299792528152\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 7, loss: 0.16922875866293907\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 8, loss: 0.16107673197984695\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 9, loss: 0.15404683724045753\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 10, loss: 0.14802725985646248\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 11, loss: 0.14287303388118744\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 12, loss: 0.1384414117783308\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 13, loss: 0.13460607454180717\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 14, loss: 0.1312607266008854\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 15, loss: 0.12831821478903294\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 16, loss: 0.12570795975625515\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 17, loss: 0.12337299063801765\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 18, loss: 0.12126746587455273\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 19, loss: 0.11935433372855186\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 20, loss: 0.11760355345904827\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 21, loss: 0.11599067784845829\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 22, loss: 0.11449568346142769\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 23, loss: 0.11310207471251488\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 24, loss: 0.11179621890187263\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 25, loss: 0.11056671850383282\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 26, loss: 0.10940407775342464\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 27, loss: 0.10830028168857098\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 28, loss: 0.10724855773150921\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 29, loss: 0.10624313540756702\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 30, loss: 0.1052790954709053\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 31, loss: 0.10435222089290619\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 32, loss: 0.10345886647701263\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 33, loss: 0.1025958750396967\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 34, loss: 0.10176053084433079\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 35, loss: 0.10095042362809181\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 36, loss: 0.10016347467899323\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 37, loss: 0.09939785115420818\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 38, loss: 0.098651934415102\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 39, loss: 0.09792428836226463\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 40, loss: 0.09721364825963974\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 41, loss: 0.09651889465749264\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 42, loss: 0.09583901800215244\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 43, loss: 0.09517310746014118\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 44, loss: 0.09452036581933498\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 45, loss: 0.09388007409870625\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 46, loss: 0.09325156360864639\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 47, loss: 0.09263425506651402\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 48, loss: 0.09202759712934494\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 49, loss: 0.09143111854791641\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 50, loss: 0.09084435924887657\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 51, loss: 0.09026693738996983\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 52, loss: 0.08969846740365028\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 53, loss: 0.08913860842585564\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 54, loss: 0.08858705498278141\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 55, loss: 0.08804351836442947\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 56, loss: 0.08750772848725319\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 57, loss: 0.08697944693267345\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 58, loss: 0.08645843341946602\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 59, loss: 0.08594449236989021\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 60, loss: 0.08543741330504417\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 61, loss: 0.08493702113628387\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 62, loss: 0.08444313518702984\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 63, loss: 0.08395559713244438\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 64, loss: 0.08347426541149616\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 65, loss: 0.08299898356199265\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 66, loss: 0.08252961747348309\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 67, loss: 0.08206604234874249\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 68, loss: 0.08160813339054585\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 69, loss: 0.08115578815340996\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 70, loss: 0.08070887438952923\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 71, loss: 0.08026731759309769\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 72, loss: 0.07983099296689034\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 73, loss: 0.07939982041716576\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 74, loss: 0.07897370308637619\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 75, loss: 0.07855254970490932\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 76, loss: 0.07813628017902374\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 77, loss: 0.07772481627762318\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 78, loss: 0.07731806859374046\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 79, loss: 0.07691597938537598\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 80, loss: 0.07651844993233681\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 81, loss: 0.07612544856965542\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 82, loss: 0.075736865401268\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 83, loss: 0.07535266131162643\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 84, loss: 0.07497274875640869\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 85, loss: 0.0745970867574215\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 86, loss: 0.07422560174018145\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 87, loss: 0.07385823410004377\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 88, loss: 0.07349492609500885\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 89, loss: 0.0731356255710125\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 90, loss: 0.07278026919811964\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 91, loss: 0.0724288085475564\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 92, loss: 0.0720811877399683\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 93, loss: 0.07173734437674284\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 94, loss: 0.07139724120497704\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 95, loss: 0.07106082327663898\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 96, loss: 0.07072803657501936\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 97, loss: 0.07039884105324745\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 98, loss: 0.07007318269461393\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 99, loss: 0.06975101679563522\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 100, loss: 0.06943229679018259\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 101, loss: 0.06911697331815958\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 102, loss: 0.06880501005798578\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 103, loss: 0.0684963557869196\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 104, loss: 0.06819096300750971\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 105, loss: 0.06788880191743374\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 106, loss: 0.06758982222527266\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 107, loss: 0.0672939857468009\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 108, loss: 0.06700124684721231\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 109, loss: 0.06671156641095877\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 110, loss: 0.06642491556704044\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 111, loss: 0.06614124123007059\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 112, loss: 0.06586051359772682\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 113, loss: 0.06558268796652555\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 114, loss: 0.06530772987753153\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 115, loss: 0.06503561232239008\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 116, loss: 0.06476627569645643\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 117, loss: 0.06449970323592424\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 118, loss: 0.06423585955053568\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 119, loss: 0.0639747017994523\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 120, loss: 0.06371619831770658\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 121, loss: 0.06346031371504068\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 122, loss: 0.06320701539516449\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 123, loss: 0.06295627355575562\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 124, loss: 0.06270804908126593\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 125, loss: 0.06246231496334076\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 126, loss: 0.06221903674304485\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 127, loss: 0.061978189274668694\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 128, loss: 0.06173973251134157\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 129, loss: 0.06150364130735397\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 130, loss: 0.06126988772302866\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 131, loss: 0.0610384326428175\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 132, loss: 0.06080926116555929\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 133, loss: 0.060582331381738186\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 134, loss: 0.06035762559622526\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 135, loss: 0.06013511028140783\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 136, loss: 0.05991474911570549\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 137, loss: 0.05969652533531189\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 138, loss: 0.059480415657162666\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 139, loss: 0.05926638841629028\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 140, loss: 0.05905440915375948\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 141, loss: 0.05884446296840906\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 142, loss: 0.05863652378320694\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 143, loss: 0.058430569246411324\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 144, loss: 0.05822655279189348\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 145, loss: 0.05802448280155659\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 146, loss: 0.05782431177794933\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 147, loss: 0.05762602761387825\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 148, loss: 0.0574295949190855\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 149, loss: 0.05723499599844217\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 150, loss: 0.05704221688210964\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 151, loss: 0.056851224042475224\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 152, loss: 0.05666199326515198\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 153, loss: 0.05647451803088188\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 154, loss: 0.056288765743374825\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 155, loss: 0.05610471311956644\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 156, loss: 0.05592234339565039\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 157, loss: 0.05574163515120745\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 158, loss: 0.05556256137788296\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 159, loss: 0.05538511835038662\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 160, loss: 0.05520927347242832\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 161, loss: 0.05503500904887915\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 162, loss: 0.0548623101785779\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 163, loss: 0.054691143333911896\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 164, loss: 0.05452151596546173\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 165, loss: 0.054353379644453526\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 166, loss: 0.05418673437088728\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 167, loss: 0.05402155872434378\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 168, loss: 0.05385783687233925\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 169, loss: 0.053695556707680225\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 170, loss: 0.05353467911481857\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 171, loss: 0.053375206887722015\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 172, loss: 0.05321711953729391\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 173, loss: 0.053060395643115044\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 174, loss: 0.05290502496063709\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 175, loss: 0.05275098513811827\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 176, loss: 0.05259825848042965\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 177, loss: 0.05244683939963579\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 178, loss: 0.05229670833796263\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 179, loss: 0.05214784760028124\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 180, loss: 0.052000248804688454\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 181, loss: 0.051853885874152184\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 182, loss: 0.05170875322073698\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 183, loss: 0.05156483594328165\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 184, loss: 0.0514221154153347\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 185, loss: 0.051280584186315536\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 186, loss: 0.05114021711051464\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 187, loss: 0.05100101325660944\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 188, loss: 0.050862944684922695\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 189, loss: 0.05072600953280926\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 190, loss: 0.05059020034968853\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 191, loss: 0.05045549105852842\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 192, loss: 0.05032187607139349\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 193, loss: 0.050189344212412834\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 194, loss: 0.05005786940455437\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 195, loss: 0.049927459098398685\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 196, loss: 0.04979808907955885\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 197, loss: 0.049669744446873665\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 198, loss: 0.049542427994310856\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 199, loss: 0.04941611923277378\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 200, loss: 0.04929081164300442\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 201, loss: 0.0491664744913578\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 202, loss: 0.049043125472962856\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 203, loss: 0.048920733854174614\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 204, loss: 0.0487992987036705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 205, loss: 0.04867880791425705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 206, loss: 0.04855924379080534\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 207, loss: 0.04844060353934765\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 208, loss: 0.048322875052690506\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 209, loss: 0.04820605181157589\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 210, loss: 0.04809011612087488\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 211, loss: 0.04797506146132946\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 212, loss: 0.0478608813136816\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 213, loss: 0.04774756357073784\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 214, loss: 0.047635097056627274\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 215, loss: 0.04752347245812416\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 216, loss: 0.0474126860499382\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 217, loss: 0.047302727587521076\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 218, loss: 0.04719358589500189\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 219, loss: 0.04708525165915489\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 220, loss: 0.04697771091014147\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 221, loss: 0.04687096830457449\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 222, loss: 0.04676501080393791\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 223, loss: 0.04665982723236084\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 224, loss: 0.04655539896339178\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 225, loss: 0.046451738104224205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 226, loss: 0.046348835341632366\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 227, loss: 0.04624665342271328\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 228, loss: 0.046145214699208736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 229, loss: 0.046044510789215565\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 230, loss: 0.045944519340991974\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 231, loss: 0.04584524221718311\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 232, loss: 0.045746663585305214\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 233, loss: 0.04564878437668085\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 234, loss: 0.045551604591310024\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 235, loss: 0.045455098152160645\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 236, loss: 0.04535927437245846\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 237, loss: 0.045264110900461674\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 238, loss: 0.045169608667492867\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 239, loss: 0.04507576674222946\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 240, loss: 0.04498257301747799\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 241, loss: 0.044890021905303\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 242, loss: 0.0447981134057045\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 243, loss: 0.04470681585371494\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 244, loss: 0.04461615812033415\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 245, loss: 0.04452610854059458\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 246, loss: 0.044436678290367126\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 247, loss: 0.04434784408658743\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 248, loss: 0.04425961244851351\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 249, loss: 0.044171975925564766\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 250, loss: 0.04408491309732199\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 251, loss: 0.04399844352155924\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 252, loss: 0.043912545777857304\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 253, loss: 0.04382721334695816\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 254, loss: 0.04374244902282953\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 255, loss: 0.04365824814885855\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 256, loss: 0.043574594892561436\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 257, loss: 0.0434914892539382\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 258, loss: 0.04340892657637596\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 259, loss: 0.04332689940929413\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 260, loss: 0.0432454077526927\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 261, loss: 0.043164439499378204\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 262, loss: 0.04308400023728609\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 263, loss: 0.043004073202610016\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 264, loss: 0.04292465187609196\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 265, loss: 0.042845748364925385\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 266, loss: 0.04276734683662653\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 267, loss: 0.0426894361153245\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 268, loss: 0.04261201433837414\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 269, loss: 0.042535096406936646\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 270, loss: 0.042458648793399334\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 271, loss: 0.042382681742310524\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 272, loss: 0.04230719804763794\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 273, loss: 0.04223218001425266\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 274, loss: 0.042157627642154694\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 275, loss: 0.04208353813737631\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 276, loss: 0.042009901255369186\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 277, loss: 0.04193672351539135\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 278, loss: 0.04186399281024933\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 279, loss: 0.041791705414652824\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 280, loss: 0.04171985574066639\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 281, loss: 0.0416484484449029\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 282, loss: 0.0415774742141366\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 283, loss: 0.04150693118572235\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 284, loss: 0.04143680725246668\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 285, loss: 0.04136710520833731\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 286, loss: 0.04129782412201166\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 287, loss: 0.041228956542909145\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 288, loss: 0.041160495951771736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 289, loss: 0.04109245166182518\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 290, loss: 0.041024803183972836\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 291, loss: 0.0409575579687953\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 292, loss: 0.040890698321163654\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 293, loss: 0.04082423634827137\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 294, loss: 0.040758173912763596\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 295, loss: 0.04069248586893082\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 296, loss: 0.040627180598676205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 297, loss: 0.04056225158274174\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 298, loss: 0.04049770347774029\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 299, loss: 0.040433524176478386\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 300, loss: 0.040369716472923756\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 301, loss: 0.04030627757310867\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 302, loss: 0.04024319630116224\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 303, loss: 0.04018047358840704\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 304, loss: 0.04011811316013336\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 305, loss: 0.04005609964951873\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 306, loss: 0.0399944419041276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 307, loss: 0.03993312967941165\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 308, loss: 0.03987216204404831\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 309, loss: 0.039811535738408566\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 310, loss: 0.03975125262513757\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 311, loss: 0.03969130339100957\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 312, loss: 0.03963168291375041\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 313, loss: 0.0395723944529891\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 314, loss: 0.03951343335211277\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 315, loss: 0.039454799611121416\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 316, loss: 0.03939648764207959\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 317, loss: 0.0393384899944067\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 318, loss: 0.03928081365302205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 319, loss: 0.03922345116734505\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 320, loss: 0.03916640346869826\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 321, loss: 0.03910966170951724\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 322, loss: 0.039053224958479404\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 323, loss: 0.038997096475213766\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 324, loss: 0.03894126368686557\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 325, loss: 0.03888574009761214\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 326, loss: 0.03883049916476011\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 327, loss: 0.03877556277438998\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 328, loss: 0.038720916491001844\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 329, loss: 0.03866655984893441\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 330, loss: 0.0386124849319458\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 331, loss: 0.038558701518923044\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 332, loss: 0.03850520448759198\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 333, loss: 0.038451981265097857\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 334, loss: 0.03839903650805354\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 335, loss: 0.03834637440741062\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 336, loss: 0.03829398052766919\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 337, loss: 0.03824185719713569\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 338, loss: 0.03819000441581011\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 339, loss: 0.03813841845840216\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 340, loss: 0.03808710305020213\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 341, loss: 0.03803604794666171\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 342, loss: 0.037985255010426044\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 343, loss: 0.03793471958488226\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 344, loss: 0.0378844472579658\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 345, loss: 0.03783442033454776\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 346, loss: 0.03778465045616031\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 347, loss: 0.03773513436317444\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 348, loss: 0.03768586693331599\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 349, loss: 0.03763684583827853\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 350, loss: 0.03758807061240077\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 351, loss: 0.03753954125568271\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 352, loss: 0.03749125171452761\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 353, loss: 0.03744320385158062\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 354, loss: 0.03739538975059986\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 355, loss: 0.03734782012179494\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 356, loss: 0.03730047447606921\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 357, loss: 0.037253370974212885\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 358, loss: 0.03720649937167764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 359, loss: 0.037159846629947424\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 360, loss: 0.037113435566425323\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 361, loss: 0.037067238707095385\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 362, loss: 0.037021271884441376\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 363, loss: 0.0369755276478827\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 364, loss: 0.036930004600435495\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 365, loss: 0.03688469575718045\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 366, loss: 0.03683961136266589\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 367, loss: 0.036794747691601515\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 368, loss: 0.036750093568116426\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 369, loss: 0.03670565132051706\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 370, loss: 0.036661419086158276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 371, loss: 0.0366173954680562\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 372, loss: 0.036573588848114014\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 373, loss: 0.03652998572215438\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 374, loss: 0.03648658515885472\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 375, loss: 0.036443385761231184\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 376, loss: 0.036400394048541784\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 377, loss: 0.03635760163888335\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 378, loss: 0.03631501505151391\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 379, loss: 0.03627261985093355\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 380, loss: 0.036230424884706736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 381, loss: 0.03618842689320445\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 382, loss: 0.03614661982282996\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 383, loss: 0.036105002742260695\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 384, loss: 0.03606357332319021\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 385, loss: 0.036022346932440996\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 386, loss: 0.035981299821287394\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 387, loss: 0.03594044502824545\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 388, loss: 0.035899769980460405\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 389, loss: 0.03585928771644831\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 390, loss: 0.035818986129015684\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 391, loss: 0.035778868943452835\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 392, loss: 0.03573892870917916\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 393, loss: 0.03569917054846883\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 394, loss: 0.03565959073603153\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 395, loss: 0.0356201846152544\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 396, loss: 0.0355809610337019\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 397, loss: 0.03554191021248698\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 398, loss: 0.03550302796065807\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 399, loss: 0.03546432591974735\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 400, loss: 0.035425787791609764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 401, loss: 0.035387429874390364\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 402, loss: 0.03534922981634736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 403, loss: 0.03531120205298066\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 404, loss: 0.035273339599370956\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 405, loss: 0.035235646180808544\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 406, loss: 0.03519811388105154\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 407, loss: 0.035160749685019255\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 408, loss: 0.03512354427948594\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 409, loss: 0.03508649254217744\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 410, loss: 0.03504961123690009\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 411, loss: 0.03501288825646043\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 412, loss: 0.03497631987556815\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 413, loss: 0.034939908888190985\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 414, loss: 0.03490365715697408\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 415, loss: 0.034867554903030396\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 416, loss: 0.03483161702752113\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 417, loss: 0.034795820247381926\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 418, loss: 0.03476017713546753\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 419, loss: 0.03472468722611666\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 420, loss: 0.03468935331329703\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 421, loss: 0.034654161892831326\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 422, loss: 0.034619121346622705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 423, loss: 0.034584220964461565\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 424, loss: 0.034549469128251076\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 425, loss: 0.03451486863195896\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 426, loss: 0.034480401780456305\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 427, loss: 0.03444609045982361\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 428, loss: 0.03441191604360938\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 429, loss: 0.03437788272276521\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 430, loss: 0.03434399701654911\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 431, loss: 0.03431023797020316\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 432, loss: 0.03427662793546915\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 433, loss: 0.03424314735457301\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 434, loss: 0.03420981531962752\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 435, loss: 0.034176604356616735\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 436, loss: 0.03414354287087917\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 437, loss: 0.03411060757935047\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 438, loss: 0.03407781198620796\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 439, loss: 0.034045142121613026\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 440, loss: 0.03401261195540428\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 441, loss: 0.03398020751774311\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 442, loss: 0.03394793486222625\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 443, loss: 0.03391578746959567\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 444, loss: 0.033883774653077126\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 445, loss: 0.03385188477113843\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 446, loss: 0.033820128068327904\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 447, loss: 0.033788494765758514\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 448, loss: 0.03375698672607541\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 449, loss: 0.03372560767456889\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 450, loss: 0.033694347366690636\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 451, loss: 0.03366320813074708\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 452, loss: 0.03363219602033496\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 453, loss: 0.033601312432438135\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 454, loss: 0.0335705429315567\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 455, loss: 0.03353988705202937\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 456, loss: 0.033509362023323774\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 457, loss: 0.03347894921898842\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 458, loss: 0.033448657020926476\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 459, loss: 0.0334184761159122\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 460, loss: 0.03338842326775193\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 461, loss: 0.03335847472772002\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 462, loss: 0.033328655175864697\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 463, loss: 0.03329893993213773\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 464, loss: 0.033269337844103575\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 465, loss: 0.0332398503087461\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 466, loss: 0.033210481982678175\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 467, loss: 0.03318121936172247\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 468, loss: 0.033152072224766016\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 469, loss: 0.03312302893027663\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 470, loss: 0.03309410251677036\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 471, loss: 0.03306528506800532\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 472, loss: 0.033036574721336365\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 473, loss: 0.03300797659903765\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 474, loss: 0.032979479525238276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 475, loss: 0.032951084431260824\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 476, loss: 0.03292280109599233\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 477, loss: 0.032894632779061794\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 478, loss: 0.03286655526608229\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 479, loss: 0.03283859230577946\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 480, loss: 0.03281072760000825\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 481, loss: 0.032782965805381536\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 482, loss: 0.03275530831888318\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 483, loss: 0.032727754674851894\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 484, loss: 0.03270029369741678\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 485, loss: 0.0326729454100132\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 486, loss: 0.03264568652957678\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 487, loss: 0.03261853661388159\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 488, loss: 0.03259148262441158\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 489, loss: 0.03256453201174736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 490, loss: 0.03253767127171159\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 491, loss: 0.032510911114513874\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 492, loss: 0.03248424641788006\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 493, loss: 0.032457676250487566\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 494, loss: 0.03243120852857828\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 495, loss: 0.03240483347326517\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 496, loss: 0.03237855341285467\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 497, loss: 0.03235236182808876\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 498, loss: 0.0323262675665319\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 499, loss: 0.032300271559506655\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "total_time 8.211915731430054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjGTO6TYf8iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}